{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка Pandas и очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import statistics as stat\n",
    "import math\n",
    "\n",
    "# импорты для построяения и обучения модели\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определяем функции для дальнейшей работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читает датасет и меняет названия колонок исходного датафрейма на более удобные\n",
    "def read_df():\n",
    "    rd_df = pd.read_csv('main_task.csv')\n",
    "    rd_df.columns = [\n",
    "        'id', 'city_name', 'cuisine', 'rank', 'rating', 'price', \n",
    "        'reviews count', 'reviews', 'url_ta', 'id_ta'\n",
    "        ]\n",
    "    return rd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляет строковые колонки\n",
    "def drop_non_numeric(ds_df):\n",
    "    for column_name in ds_df:\n",
    "        type = ds_df[column_name].dtype\n",
    "        if type not in ['int64', 'float64']:\n",
    "            df.drop(column_name, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляет колонки с пропусками\n",
    "def fill_gaps(ds_df, value):\n",
    "    for column_name in ds_df:\n",
    "        if ds_df[column_name].isna().value_counts()[False] < ds_df.shape[0]:\n",
    "            ds_df[column_name].fillna(value = value, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирует модель и выводит МАЕ    \n",
    "def test_model(tm_df):\n",
    "    drop_non_numeric(tm_df)\n",
    "    fill_gaps(tm_df, 0)\n",
    "    X = tm_df.drop(['rating'], axis = 1)\n",
    "    y = tm_df['rating']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    regr = RandomForestRegressor(n_estimators=100)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем исходный датасет, удалив строки и пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.435622595436508\n"
     ]
    }
   ],
   "source": [
    "df = read_df()\n",
    "test_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Колонки\n",
    "Поочередно работаем с колонками, пытаясь преобразовать данные или создать новые на их основе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----> id\n",
    "Преобразуем id в число."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_as_int(iai_df):\n",
    "    iai_df['id'] = iai_df['id'].str[3:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.4188190333333333\n"
     ]
    }
   ],
   "source": [
    "df = read_df()\n",
    "id_as_int(df)\n",
    "test_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат улучшился, значит двигаемся в правильном направлении =)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----> city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим информацию о том, является ли город столицей, как далеко от столицы он расположен, в какой стране он находится, его неселение и плотность неселения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим новые данные о  городах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_insights(ci_df):\n",
    "    # вставим новые столбцы\n",
    "    ci_df.insert(1, 'city_name_length', ci_df['city_name'].str.len()) # длина имени города\n",
    "    ci_df.insert(2, 'city_count', 0) # кол-во ресторанов из датасета в этом городе\n",
    "    ci_df.insert(3, 'city_id', 0) # числовой идентификатор города\n",
    "    ci_df.insert(4, 'country_id', 0) # числовой идентификатор страны\n",
    "    ci_df.insert(5, 'is_in_capital', 0) # является ли город столицей\n",
    "    ci_df.insert(6, 'far_from_capital', 0) # удаленность города от столицы\n",
    "    ci_df.insert(7, 'city_population', 0) # население города\n",
    "    ci_df.insert(8, 'city_density', 0) # плотность населения города\n",
    "    \n",
    "    # список стран\n",
    "    countries = [\n",
    "        'UK', 'France', 'Spain', 'Germany', 'Italy', 'Czech Republic', 'Portugal', 'Austria', \n",
    "        'Netherlands', 'Belgium', 'Sweden', 'Hungary', 'Poland', 'Ireland', 'Denmark', 'Greece',\n",
    "        'Switzerland', 'Norway', 'Finland', 'Slovakia', 'Luxembourg', 'Slovenia'\n",
    "        ]\n",
    "    \n",
    "    # словарь городов\n",
    "    df_cities = df['city_name'].value_counts().reset_index()\n",
    "    df_cities.columns = ['name', 'count']\n",
    "    cities = {}\n",
    "    count = df_cities['name'].size\n",
    "    for i in range(0, count):\n",
    "        city = df_cities.loc[i]\n",
    "        cities[city['name']] = {\n",
    "            'id': int(i),\n",
    "            'count': city['count']\n",
    "        }\n",
    "    cities['London'].update({\n",
    "        'country_id': countries.index('UK'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 9304,\n",
    "        'density': 5590,\n",
    "    })\n",
    "    cities['Paris'].update({\n",
    "        'country_id': countries.index('France'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 2148,\n",
    "        'density': 21000,\n",
    "    })\n",
    "    cities['Madrid'].update({\n",
    "        'country_id': countries.index('Spain'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 6618,\n",
    "        'density': 5337,\n",
    "    })\n",
    "    cities['Barcelona'].update({\n",
    "        'country_id': countries.index('Spain'),\n",
    "        'is_capital': 0,\n",
    "        'far_from_capital': 504,\n",
    "        'population': 5586,\n",
    "        'density': 16000,\n",
    "    })\n",
    "    cities['Berlin'].update({\n",
    "        'country_id': countries.index('Germany'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 3562038,\n",
    "        'density': 3809,\n",
    "    })\n",
    "    cities['Milan'].update({\n",
    "        'country_id': countries.index('Italy'),\n",
    "        'is_capital': 0,\n",
    "        'far_from_capital': 477,\n",
    "        'population': 3140000,\n",
    "        'density': 7700,\n",
    "    })\n",
    "    cities['Rome'].update({\n",
    "        'country_id': countries.index('Italy'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 4257000,\n",
    "        'density': 2232,\n",
    "    })\n",
    "    cities['Prague'].update({\n",
    "        'country_id': countries.index('Czech Republic'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 1305737,\n",
    "        'density': 2700,\n",
    "    })\n",
    "    cities['Lisbon'].update({\n",
    "        'country_id': countries.index('Portugal'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 2957000,\n",
    "        'density': 4883,\n",
    "    })\n",
    "    cities['Vienna'].update({\n",
    "        'country_id': countries.index('Austria'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 2957000,\n",
    "        'density': 16000,\n",
    "    })\n",
    "    cities['Amsterdam'].update({\n",
    "        'country_id': countries.index('Netherlands'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 1149000,\n",
    "        'density': 4908,\n",
    "    })\n",
    "    cities['Brussels'].update({\n",
    "        'country_id': countries.index('Belgium'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 2080788,\n",
    "        'density': 5384,\n",
    "    })\n",
    "    cities['Hamburg'].update({\n",
    "        'country_id': countries.index('Germany'),\n",
    "        'is_capital': 0,\n",
    "        'far_from_capital': 255,\n",
    "        'population': 1790000,\n",
    "        'density': 2320,\n",
    "    })\n",
    "    cities['Munich'].update({\n",
    "        'country_id': countries.index('Germany'),\n",
    "        'is_capital': 0,\n",
    "        'far_from_capital': 255,\n",
    "        'population': 1538000,\n",
    "        'density': 4500,\n",
    "    })\n",
    "    cities['Lyon'].update({\n",
    "        'country_id': countries.index('France'),\n",
    "        'is_capital': 0,\n",
    "        'far_from_capital': 393,\n",
    "        'population': 1719000,\n",
    "        'density': 10000,\n",
    "    })\n",
    "    cities['Stockholm'].update({\n",
    "        'country_id': countries.index('Sweden'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 1633000,\n",
    "        'density': 4800,\n",
    "    })\n",
    "    cities['Budapest'].update({\n",
    "        'country_id': countries.index('Hungary'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 1768073,\n",
    "        'density': 3351,\n",
    "    })\n",
    "    cities['Warsaw'].update({\n",
    "        'country_id': countries.index('Poland'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 1783000,\n",
    "        'density': 3372,\n",
    "    })\n",
    "    cities['Dublin'].update({\n",
    "        'country_id': countries.index('Ireland'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 1228179,\n",
    "        'density': 4588,\n",
    "    })\n",
    "    cities['Copenhagen'].update({\n",
    "        'country_id': countries.index('Denmark'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 1346000,\n",
    "        'density': 4400,\n",
    "    })\n",
    "    cities['Athens'].update({\n",
    "        'country_id': countries.index('Greece'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 3153000,\n",
    "        'density': 17040,\n",
    "    })\n",
    "    cities['Edinburgh'].update({\n",
    "        'country_id': countries.index('UK'),\n",
    "        'is_capital': 0,\n",
    "        'far_from_capital': 534,\n",
    "        'population': 537000,\n",
    "        'density': 1830,\n",
    "    })\n",
    "    cities['Zurich'].update({\n",
    "        'country_id': countries.index('Switzerland'),\n",
    "        'is_capital': 0,\n",
    "        'far_from_capital': 95,\n",
    "        'population': 1395356,\n",
    "        'density': 4700,\n",
    "    })\n",
    "    cities['Oporto'].update({\n",
    "        'country_id': countries.index('Portugal'),\n",
    "        'is_capital': 0,\n",
    "        'far_from_capital': 300,\n",
    "        'population': 1313000,\n",
    "        'density': 6900,\n",
    "    })\n",
    "    cities['Geneva'].update({\n",
    "        'country_id': countries.index('Switzerland'),\n",
    "        'is_capital': 0,\n",
    "        'far_from_capital': 130,\n",
    "        'population': 613373,\n",
    "        'density': 12000,\n",
    "    })\n",
    "    cities['Krakow'].update({\n",
    "        'country_id': countries.index('Poland'),\n",
    "        'is_capital': 0,\n",
    "        'far_from_capital': 252,\n",
    "        'population': 768731,\n",
    "        'density': 2328,\n",
    "    })\n",
    "    cities['Oslo'].update({\n",
    "        'country_id': countries.index('Norway'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 693491,\n",
    "        'density': 1645,\n",
    "    })\n",
    "    cities['Helsinki'].update({\n",
    "        'country_id': countries.index('Finland'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 1305000,\n",
    "        'density': 3035,\n",
    "    })\n",
    "    cities['Bratislava'].update({\n",
    "        'country_id': countries.index('Slovakia'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 435000,\n",
    "        'density': 1169,\n",
    "    })\n",
    "    cities['Luxembourg'].update({\n",
    "        'country_id': countries.index('Luxembourg'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 625978,\n",
    "        'density': 242,\n",
    "    })\n",
    "    cities['Ljubljana'].update({\n",
    "        'country_id': countries.index('Slovenia'),\n",
    "        'is_capital': 1,\n",
    "        'far_from_capital': 0,\n",
    "        'population': 625978,\n",
    "        'density': 1712,\n",
    "    })\n",
    "        \n",
    "    # заполняем столбцы\n",
    "    for city_name, city_data in cities.items():\n",
    "        ci_df.loc[ci_df['city_name'] == city_name, 'city_id'] = int(city_data['id'])\n",
    "        ci_df.loc[ci_df['city_name'] == city_name, 'city_count'] = int(city_data['count'])\n",
    "        ci_df.loc[ci_df['city_name'] == city_name, 'country_id'] = int(city_data['country_id'])\n",
    "        ci_df.loc[ci_df['city_name'] == city_name, 'is_in_capital'] = int(city_data['is_capital'])\n",
    "        ci_df.loc[ci_df['city_name'] == city_name, 'far_from_capital'] = int(city_data['far_from_capital'])\n",
    "        ci_df.loc[ci_df['city_name'] == city_name, 'city_population'] = int(city_data['population'])\n",
    "        ci_df.loc[ci_df['city_name'] == city_name, 'city_density'] = int(city_data['density'])\n",
    "        \n",
    "    df.drop('city_name', axis = 'columns', inplace = True)        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.21818800000000002\n"
     ]
    }
   ],
   "source": [
    "df = read_df()\n",
    "id_as_int(df)\n",
    "city_insights(df)\n",
    "test_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поробуем сделать dummy-переменные из города и из страны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_dummies(cd_df):\n",
    "    cd_df = pd.get_dummies(cd_df, columns = ['city_id'], prefix = 'city_id_')\n",
    "    return cd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_dummies(cd_df):\n",
    "    cd_df = pd.get_dummies(cd_df, columns = ['country_id'], prefix = 'country_id_')\n",
    "    return cd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.21755649999999996\n"
     ]
    }
   ],
   "source": [
    "df = read_df()\n",
    "\n",
    "id_as_int(df)\n",
    "\n",
    "city_insights(df)\n",
    "df = city_dummies(df)\n",
    "df = country_dummies(df)\n",
    "\n",
    "test_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----> cuisine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски самыми часто встречающимися кухнями и сделаем кухни списком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuisine_prepare(cp_df):\n",
    "    cp_df['cuisine'] = cp_df['cuisine'].fillna(\"['other']\")\n",
    "    cp_df['cuisine'] = cp_df['cuisine'] \\\n",
    "        .str.replace(\"'\", '') \\\n",
    "        .str.replace(\"\\[\", '') \\\n",
    "        .str.replace(\"\\]\", '') \\\n",
    "        .str.split(', ');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем кол-во кухонь в каждом ресторане."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuisine_count(cc_df):\n",
    "    cuisine_index = list(cc_df.columns).index('cuisine')\n",
    "    cc_df.insert(cuisine_index + 1, 'cuisines_count', None)\n",
    "    cc_df['cuisines_count'] = cc_df['cuisine'].apply(lambda c: len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Превратим кухни в dummy-переменные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuisine_dummies(cd_df):\n",
    "    cuisines = set(cd_df['cuisine'].explode().tolist())\n",
    "    for cuisine_name in cuisines:\n",
    "        column_name = 'cuisine_' + cuisine_name.lower().replace(' ', '_')\n",
    "        cd_df[column_name] = cd_df['cuisine'].apply(lambda cuisines: int(cuisine_name in cuisines))\n",
    "    df.drop('cuisine', axis = 'columns', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.20826750000000002\n"
     ]
    }
   ],
   "source": [
    "df = read_df()\n",
    "\n",
    "id_as_int(df)\n",
    "\n",
    "city_insights(df)\n",
    "df = city_dummies(df)\n",
    "df = country_dummies(df)\n",
    "\n",
    "cuisine_prepare(df)\n",
    "cuisine_count(df)\n",
    "cuisine_dummies(df)\n",
    "\n",
    "test_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----> price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Превратим ценовую категорию в числовой признак заменив пропуски на среднюю ценовую категорию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_zone(price):\n",
    "        if price == '$':\n",
    "            return 0\n",
    "        elif price == '$$ - $$$':\n",
    "            return 1\n",
    "        elif price == '$$$$':\n",
    "            return 2\n",
    "        \n",
    "\n",
    "def price_number(pn_df):\n",
    "    pn_df['price'].fillna('$$ - $$$', inplace=True)\n",
    "    pn_df['price'] = pn_df['price'].apply(price_zone).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.20895650000000002\n"
     ]
    }
   ],
   "source": [
    "df = read_df()\n",
    "\n",
    "id_as_int(df)\n",
    "\n",
    "city_insights(df)\n",
    "df = city_dummies(df)\n",
    "df = country_dummies(df)\n",
    "\n",
    "cuisine_prepare(df)\n",
    "cuisine_count(df)\n",
    "cuisine_dummies(df)\n",
    "\n",
    "price_number(df)\n",
    "\n",
    "test_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----> reviews count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски средним количеством отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reviews_count(mrc_df):\n",
    "    mrc_df['reviews count'].fillna(value = mrc_df['reviews count'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.20804\n"
     ]
    }
   ],
   "source": [
    "df = read_df()\n",
    "\n",
    "id_as_int(df)\n",
    "\n",
    "city_insights(df)\n",
    "df = city_dummies(df)\n",
    "df = country_dummies(df)\n",
    "\n",
    "cuisine_prepare(df)\n",
    "cuisine_count(df)\n",
    "cuisine_dummies(df)\n",
    "\n",
    "price_number(df)\n",
    "\n",
    "mean_reviews_count(df)\n",
    "\n",
    "test_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что поле с кол-вом отзывов ухудшило результат. Скорее свего нам придется его удалить. Сделаем это позже, после того как посмотрим корреляцию у всех полей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----> reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем время, прошедшее с последнего отзыва и время между отзывами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_reviews_dates(string):\n",
    "    split_position = string.find('], [')\n",
    "    reviews_end_position = split_position\n",
    "    dates_start_position = split_position + 4\n",
    "    reviews_string = string[0:reviews_end_position].replace('[', '')\n",
    "    dates_string = string[dates_start_position:].replace(']', '')\n",
    "    reviews = list(map(lambda review: review[1:-1], reviews_string.split(', ')))\n",
    "    dates = list(map(lambda date: date[1:-1], dates_string.split(', ')))\n",
    "    reviews = list(filter(lambda item: len(item) > 0, reviews))\n",
    "    dates = list(filter(lambda item: len(item) > 0, dates))\n",
    "    dates = list(map(lambda item: datetime.strptime(item, '%m/%d/%Y'), dates))\n",
    "    return reviews, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews_list(string):\n",
    "    return split_reviews_dates(string)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates_list(string):\n",
    "    return split_reviews_dates(string)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_date(string):\n",
    "    dates = get_dates_list(string)\n",
    "    if len(dates) > 0:\n",
    "        return max(dates)\n",
    "    else:\n",
    "        return datetime.strptime('01/01/1971', '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_between(string):\n",
    "    dates = get_dates_list(string)\n",
    "    if len(dates) > 1:\n",
    "        diffs = []\n",
    "        for i in range(1, len(dates)):\n",
    "            diffs.append(abs((dates[i] - dates[i-1]).days))\n",
    "        return  stat.mean(diffs)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_from_last_review(string):\n",
    "    last_date = get_last_date(string)\n",
    "    now = datetime.now()\n",
    "    from_last = now - last_date\n",
    "    return from_last.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    " def reviews_insights(ri_df):\n",
    "    ri_df['reviews'] = ri_df['reviews'].str.replace('\\\"', '').str.replace('\\\"', '');\n",
    "    reviews_index = list(ri_df.columns).index('reviews')\n",
    "    df.insert(reviews_index + 1, 'reviews_count', None)\n",
    "    df.insert(reviews_index + 2, 'time_between_reviews', None)\n",
    "    df.insert(reviews_index + 3, 'time_from_last_review', None)\n",
    "    df['reviews_count'] = df['reviews'].map(lambda reviews: len(get_reviews_list(reviews)))\n",
    "    df['time_between_reviews'] = df['reviews'].map(lambda reviews: get_time_between(reviews))\n",
    "    df['time_from_last_review'] = df['reviews'].map(get_time_from_last_review)\n",
    "    df.drop('reviews', axis = 'columns', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.20868699999999998\n"
     ]
    }
   ],
   "source": [
    "df = read_df()\n",
    "\n",
    "id_as_int(df)\n",
    "\n",
    "city_insights(df)\n",
    "df = city_dummies(df)\n",
    "df = country_dummies(df)\n",
    "\n",
    "cuisine_prepare(df)\n",
    "cuisine_count(df)\n",
    "cuisine_dummies(df)\n",
    "\n",
    "price_number(df)\n",
    "\n",
    "mean_reviews_count(df)\n",
    "\n",
    "reviews_insights(df)\n",
    "\n",
    "test_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----> url_ta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень интересное поле. Понятно, что можно спарсить оттуда много чего интересного и посмотреть, что получится, но, к сожалению, времени на это нет. Просто удалим.\n",
    "\n",
    "Хотя, если честно, непонятно зачем предсказывать рейтинг ресторана на трипэдвизоре, имея доступ к странице ресторана на нем же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_url_ta(dut_df):\n",
    "    df.drop('url_ta', axis = 'columns', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----> id_ta\n",
    "Преобразуем id_ta в число, предполагая, что id может нам показать давность появления ресторана в базе данных tripadvisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_ta_as_int(itai_df):\n",
    "    itai_df['id_ta'] = itai_df['id_ta'].str[1:].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим корреляцию по признакам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ForTrain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-49a8c4bc3c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m sns.heatmap(df[df.ForTrain].drop(['ForTrain'], axis=1).corr(), square=True,\n\u001b[0m\u001b[1;32m      5\u001b[0m             annot=True, fmt=\".1f\", linewidths=0.1, cmap=\"RdBu\");\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ForTrain'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (15,15)\n",
    "sns.heatmap(df[df.ForTrain].drop(['ForTrain'], axis=1).corr(), square=True,\n",
    "            annot=True, fmt=\".1f\", linewidths=0.1, cmap=\"RdBu\");\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_df()\n",
    "\n",
    "id_as_int(df)\n",
    "\n",
    "city_insights(df)\n",
    "df = city_dummies(df)\n",
    "df = country_dummies(df)\n",
    "\n",
    "cuisine_prepare(df)\n",
    "cuisine_count(df)\n",
    "cuisine_dummies(df)\n",
    "\n",
    "price_number(df)\n",
    "\n",
    "mean_reviews_count(df)\n",
    "\n",
    "reviews_insights(df)\n",
    "\n",
    "drop_url_ta(df)\n",
    "\n",
    "id_ta_as_int(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разбиваем датафрейм на части, необходимые для обучения и тестирования модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Х - данные с информацией о ресторанах, у - целевая переменная (рейтинги ресторанов)\n",
    "X = df.drop(['rating'], axis = 1)\n",
    "y = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем специальный инструмент для разбивки:\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наборы данных с меткой \"train\" будут использоваться для обучения модели, \"test\" - для тестирования.\n",
    "# Для тестирования мы будем использовать 25% от исходного датасета.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаём, обучаем и тестируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель\n",
    "regr = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# Обучаем модель на тестовом наборе данных\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
